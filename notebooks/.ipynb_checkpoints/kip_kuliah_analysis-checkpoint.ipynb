{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3eafe29b",
   "metadata": {},
   "source": [
    "# Analisis KIP Kuliah: Clustering dan Classification Workflow\n",
    "\n",
    "## Tujuan Analisis\n",
    "1. **Clustering (Unsupervised)**: Mengidentifikasi pola/tipologi pendaftar KIP Kuliah\n",
    "2. **Classification (Supervised)**: Membangun model prediksi berdasarkan cluster\n",
    "3. **Model Selection**: Membandingkan performa berbagai algoritma ML\n",
    "4. **Interpretasi**: Menganalisis faktor-faktor yang paling berpengaruh\n",
    "\n",
    "## Workflow\n",
    "Clustering → Classification → Model Selection → Interpretasi → Export Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c289329",
   "metadata": {},
   "source": [
    "## 1. Setup Project Structure dan Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7d5ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup folder structure\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create folder structure if not exists\n",
    "folders = ['data', 'models', 'results']\n",
    "for folder in folders:\n",
    "    os.makedirs(f'../{folder}', exist_ok=True)\n",
    "    \n",
    "print(\"Project structure ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf689a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Clustering algorithms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "\n",
    "# Classification algorithms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "# Model evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# For Excel export\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66721950",
   "metadata": {},
   "source": [
    "## 2. Load dan Explore Data KIP Kuliah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bffb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all KIP Kuliah data\n",
    "def load_kip_data():\n",
    "    \"\"\"\n",
    "    Load and combine all KIP Kuliah data from different years\n",
    "    \"\"\"\n",
    "    base_path = Path('../Bahan Laporan KIP Kuliah 2022 s.d 2024')\n",
    "    \n",
    "    # Define file mappings\n",
    "    pendaftar_files = {\n",
    "        2022: [\n",
    "            'CSV_Pendaftar/2022/Siswa_Pendaftar_SBMPN_2022.csv',\n",
    "            'CSV_Pendaftar/2022/Siswa_Pendaftar_Seleksi Mandiri PTN_2022.csv',\n",
    "            'CSV_Pendaftar/2022/Siswa_Pendaftar_SNMPN_Politeknik Negeri Cilacap_20220328.csv'\n",
    "        ],\n",
    "        2023: [\n",
    "            'CSV_Pendaftar/2023/pendaftar kip jalur SNBT 2023.csv',\n",
    "            'CSV_Pendaftar/2023/pendaftar KIP Kuliah 2023 jalur SNBP.csv',\n",
    "            'CSV_Pendaftar/2023/Siswa_Pendaftar_Seleksi Mandiri PTN_2023.csv'\n",
    "        ],\n",
    "        2024: [\n",
    "            'CSV_Pendaftar/2024/pendaftar kip jalur snbp dan snbt 2024.csv'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    penerima_files = {\n",
    "        2022: 'CSV_Penerima/penerima KIP Kuliah angkatan 2022.csv',\n",
    "        2023: 'CSV_Penerima/penerima KIP Kuliah angkatan 2023.csv',\n",
    "        2024: 'CSV_Penerima/penerima KIP Kuliah angkatan 2024.csv'\n",
    "    }\n",
    "    \n",
    "    all_pendaftar = []\n",
    "    all_penerima = []\n",
    "    \n",
    "    # Load pendaftar data\n",
    "    for year, files in pendaftar_files.items():\n",
    "        for file in files:\n",
    "            try:\n",
    "                df = pd.read_csv(base_path / file)\n",
    "                df['tahun'] = year\n",
    "                df['jalur'] = file.split('/')[-1].replace('.csv', '')\n",
    "                all_pendaftar.append(df)\n",
    "                print(f\"Loaded {file}: {len(df)} records\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    # Load penerima data\n",
    "    for year, file in penerima_files.items():\n",
    "        try:\n",
    "            df = pd.read_csv(base_path / file)\n",
    "            df['tahun'] = year\n",
    "            df['status'] = 'diterima'\n",
    "            all_penerima.append(df)\n",
    "            print(f\"Loaded {file}: {len(df)} records\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file}: {e}\")\n",
    "    \n",
    "    # Combine data\n",
    "    pendaftar_df = pd.concat(all_pendaftar, ignore_index=True) if all_pendaftar else pd.DataFrame()\n",
    "    penerima_df = pd.concat(all_penerima, ignore_index=True) if all_penerima else pd.DataFrame()\n",
    "    \n",
    "    return pendaftar_df, penerima_df\n",
    "\n",
    "# Load data\n",
    "pendaftar_df, penerima_df = load_kip_data()\n",
    "\n",
    "print(f\"\\nTotal pendaftar: {len(pendaftar_df)}\")\n",
    "print(f\"Total penerima: {len(penerima_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ded60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data structure\n",
    "print(\"=== STRUKTUR DATA PENDAFTAR ===\")\n",
    "print(f\"Shape: {pendaftar_df.shape}\")\n",
    "print(f\"Columns: {list(pendaftar_df.columns)}\")\n",
    "print(\"\\nData types:\")\n",
    "print(pendaftar_df.dtypes)\n",
    "\n",
    "print(\"\\n=== MISSING VALUES ===\")\n",
    "missing_data = pendaftar_df.isnull().sum()\n",
    "missing_percentage = (missing_data / len(pendaftar_df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "print(missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b36833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data preview\n",
    "print(\"=== SAMPLE DATA ===\")\n",
    "display(pendaftar_df.head())\n",
    "\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "display(pendaftar_df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221a59c",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing untuk Mixed Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc5e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_kip_data(df):\n",
    "    \"\"\"\n",
    "    Preprocess KIP data for clustering and classification\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying original data\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df_processed.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    # Remove columns that are too specific (like IDs, names)\n",
    "    exclude_cols = [col for col in categorical_cols if any(keyword in col.lower() \n",
    "                   for keyword in ['id', 'nama', 'name', 'no', 'nik', 'nisn'])]\n",
    "    \n",
    "    categorical_cols = [col for col in categorical_cols if col not in exclude_cols]\n",
    "    \n",
    "    print(f\"Numerical columns: {numerical_cols}\")\n",
    "    print(f\"Categorical columns: {categorical_cols}\")\n",
    "    print(f\"Excluded columns: {exclude_cols}\")\n",
    "    \n",
    "    # Handle missing values\n",
    "    # For numerical: fill with median\n",
    "    for col in numerical_cols:\n",
    "        if col in df_processed.columns:\n",
    "            df_processed[col] = df_processed[col].fillna(df_processed[col].median())\n",
    "    \n",
    "    # For categorical: fill with mode or 'Unknown'\n",
    "    for col in categorical_cols:\n",
    "        if col in df_processed.columns:\n",
    "            mode_val = df_processed[col].mode()\n",
    "            fill_val = mode_val[0] if len(mode_val) > 0 else 'Unknown'\n",
    "            df_processed[col] = df_processed[col].fillna(fill_val)\n",
    "    \n",
    "    # Select only relevant columns for analysis\n",
    "    analysis_cols = numerical_cols + categorical_cols\n",
    "    analysis_cols = [col for col in analysis_cols if col in df_processed.columns]\n",
    "    \n",
    "    df_analysis = df_processed[analysis_cols].copy()\n",
    "    \n",
    "    return df_analysis, numerical_cols, categorical_cols\n",
    "\n",
    "# Preprocess data\n",
    "df_analysis, num_cols, cat_cols = preprocess_kip_data(pendaftar_df)\n",
    "\n",
    "print(f\"\\nFinal analysis dataset shape: {df_analysis.shape}\")\n",
    "print(f\"Missing values after preprocessing: {df_analysis.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de8da52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for K-Prototypes (mixed data clustering)\n",
    "def prepare_for_kprototypes(df, numerical_cols, categorical_cols):\n",
    "    \"\"\"\n",
    "    Prepare data for K-Prototypes algorithm\n",
    "    \"\"\"\n",
    "    # Ensure we have both types of data\n",
    "    available_num_cols = [col for col in numerical_cols if col in df.columns]\n",
    "    available_cat_cols = [col for col in categorical_cols if col in df.columns]\n",
    "    \n",
    "    # Create final dataset\n",
    "    all_cols = available_num_cols + available_cat_cols\n",
    "    df_final = df[all_cols].copy()\n",
    "    \n",
    "    # Normalize numerical data\n",
    "    scaler = StandardScaler()\n",
    "    if available_num_cols:\n",
    "        df_final[available_num_cols] = scaler.fit_transform(df_final[available_num_cols])\n",
    "    \n",
    "    # Get categorical indices for K-Prototypes\n",
    "    categorical_indices = list(range(len(available_num_cols), len(all_cols)))\n",
    "    \n",
    "    return df_final, categorical_indices, scaler, available_num_cols, available_cat_cols\n",
    "\n",
    "# Prepare data\n",
    "df_cluster, cat_indices, scaler, final_num_cols, final_cat_cols = prepare_for_kprototypes(\n",
    "    df_analysis, num_cols, cat_cols\n",
    ")\n",
    "\n",
    "print(f\"Data prepared for clustering:\")\n",
    "print(f\"Shape: {df_cluster.shape}\")\n",
    "print(f\"Numerical columns: {final_num_cols}\")\n",
    "print(f\"Categorical columns: {final_cat_cols}\")\n",
    "print(f\"Categorical indices: {cat_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056baaec",
   "metadata": {},
   "source": [
    "## 4. Clustering Analysis dengan Mixed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine optimal number of clusters\n",
    "def find_optimal_clusters(data, categorical_indices, max_k=10):\n",
    "    \"\"\"\n",
    "    Find optimal number of clusters using cost function\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    K_range = range(2, max_k + 1)\n",
    "    \n",
    "    for k in K_range:\n",
    "        try:\n",
    "            kproto = KPrototypes(n_clusters=k, init='Huang', verbose=0, random_state=42)\n",
    "            kproto.fit(data, categorical=categorical_indices)\n",
    "            costs.append(kproto.cost_)\n",
    "            print(f\"K={k}: Cost={kproto.cost_:.2f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error with K={k}: {e}\")\n",
    "            costs.append(np.inf)\n",
    "    \n",
    "    return K_range, costs\n",
    "\n",
    "# Find optimal clusters\n",
    "if len(cat_indices) > 0:  # If we have categorical data\n",
    "    print(\"Finding optimal number of clusters with K-Prototypes...\")\n",
    "    k_range, costs = find_optimal_clusters(df_cluster.values, cat_indices)\n",
    "    \n",
    "    # Plot elbow curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(k_range, costs, 'bo-')\n",
    "    plt.xlabel('Number of Clusters (K)')\n",
    "    plt.ylabel('Cost')\n",
    "    plt.title('K-Prototypes Elbow Method')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Find elbow point\n",
    "    optimal_k = k_range[np.argmin(costs)]\n",
    "    print(f\"\\nOptimal number of clusters: {optimal_k}\")\n",
    "else:\n",
    "    print(\"No categorical data found, using standard K-Means\")\n",
    "    optimal_k = 4  # Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bc37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering\n",
    "def perform_clustering(data, categorical_indices, n_clusters):\n",
    "    \"\"\"\n",
    "    Perform K-Prototypes clustering\n",
    "    \"\"\"\n",
    "    if len(categorical_indices) > 0:\n",
    "        # Use K-Prototypes for mixed data\n",
    "        kproto = KPrototypes(n_clusters=n_clusters, init='Huang', verbose=1, random_state=42)\n",
    "        cluster_labels = kproto.fit_predict(data, categorical=categorical_indices)\n",
    "        model = kproto\n",
    "        model_type = 'K-Prototypes'\n",
    "    else:\n",
    "        # Use K-Means for numerical only data\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        cluster_labels = kmeans.fit_predict(data)\n",
    "        model = kmeans\n",
    "        model_type = 'K-Means'\n",
    "    \n",
    "    return cluster_labels, model, model_type\n",
    "\n",
    "# Perform clustering\n",
    "cluster_labels, clustering_model, model_type = perform_clustering(\n",
    "    df_cluster.values, cat_indices, optimal_k\n",
    ")\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "df_cluster['cluster'] = cluster_labels\n",
    "df_analysis['cluster'] = cluster_labels\n",
    "\n",
    "print(f\"\\nClustering completed using {model_type}\")\n",
    "print(f\"Cluster distribution:\")\n",
    "print(pd.Series(cluster_labels).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34341f10",
   "metadata": {},
   "source": [
    "## 5. Visualisasi dan Analisis Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d404be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster visualization\n",
    "def visualize_clusters(df, numerical_cols, categorical_cols, cluster_col='cluster'):\n",
    "    \"\"\"\n",
    "    Create comprehensive cluster visualizations\n",
    "    \"\"\"\n",
    "    n_clusters = df[cluster_col].nunique()\n",
    "    \n",
    "    # 1. Cluster distribution\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # Cluster size distribution\n",
    "    plt.subplot(2, 3, 1)\n",
    "    cluster_counts = df[cluster_col].value_counts().sort_index()\n",
    "    plt.bar(cluster_counts.index, cluster_counts.values)\n",
    "    plt.title('Cluster Size Distribution')\n",
    "    plt.xlabel('Cluster')\n",
    "    plt.ylabel('Number of Records')\n",
    "    \n",
    "    # 2. Numerical features by cluster (if available)\n",
    "    if numerical_cols:\n",
    "        for i, col in enumerate(numerical_cols[:4]):  # Show first 4 numerical columns\n",
    "            if col in df.columns:\n",
    "                plt.subplot(2, 3, i + 2)\n",
    "                for cluster_id in sorted(df[cluster_col].unique()):\n",
    "                    cluster_data = df[df[cluster_col] == cluster_id][col]\n",
    "                    plt.hist(cluster_data, alpha=0.7, label=f'Cluster {cluster_id}', bins=20)\n",
    "                plt.title(f'{col} by Cluster')\n",
    "                plt.xlabel(col)\n",
    "                plt.ylabel('Frequency')\n",
    "                plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Categorical features analysis\n",
    "    if categorical_cols:\n",
    "        for col in categorical_cols[:3]:  # Show first 3 categorical columns\n",
    "            if col in df.columns:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                \n",
    "                # Create crosstab\n",
    "                crosstab = pd.crosstab(df[col], df[cluster_col])\n",
    "                \n",
    "                # Plot stacked bar chart\n",
    "                crosstab.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "                plt.title(f'{col} Distribution by Cluster')\n",
    "                plt.xlabel(col)\n",
    "                plt.ylabel('Count')\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.legend(title='Cluster')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "visualize_clusters(df_analysis, final_num_cols, final_cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf37545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster profiling\n",
    "def create_cluster_profile(df, numerical_cols, categorical_cols, cluster_col='cluster'):\n",
    "    \"\"\"\n",
    "    Create detailed cluster profiles\n",
    "    \"\"\"\n",
    "    profiles = {}\n",
    "    \n",
    "    for cluster_id in sorted(df[cluster_col].unique()):\n",
    "        cluster_data = df[df[cluster_col] == cluster_id]\n",
    "        profile = {'size': len(cluster_data)}\n",
    "        \n",
    "        # Numerical features statistics\n",
    "        if numerical_cols:\n",
    "            num_stats = cluster_data[numerical_cols].describe()\n",
    "            profile['numerical'] = num_stats\n",
    "        \n",
    "        # Categorical features mode\n",
    "        if categorical_cols:\n",
    "            cat_stats = {}\n",
    "            for col in categorical_cols:\n",
    "                if col in cluster_data.columns:\n",
    "                    mode_info = cluster_data[col].value_counts()\n",
    "                    cat_stats[col] = {\n",
    "                        'most_common': mode_info.index[0] if len(mode_info) > 0 else 'N/A',\n",
    "                        'frequency': mode_info.iloc[0] if len(mode_info) > 0 else 0,\n",
    "                        'percentage': (mode_info.iloc[0] / len(cluster_data) * 100) if len(mode_info) > 0 else 0\n",
    "                    }\n",
    "            profile['categorical'] = cat_stats\n",
    "        \n",
    "        profiles[f'Cluster_{cluster_id}'] = profile\n",
    "    \n",
    "    return profiles\n",
    "\n",
    "# Create cluster profiles\n",
    "cluster_profiles = create_cluster_profile(df_analysis, final_num_cols, final_cat_cols)\n",
    "\n",
    "# Display profiles\n",
    "for cluster_name, profile in cluster_profiles.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{cluster_name} (Size: {profile['size']})\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if 'numerical' in profile:\n",
    "        print(\"\\nNumerical Features (Mean):\")\n",
    "        for col in profile['numerical'].columns:\n",
    "            mean_val = profile['numerical'].loc['mean', col]\n",
    "            print(f\"  {col}: {mean_val:.2f}\")\n",
    "    \n",
    "    if 'categorical' in profile:\n",
    "        print(\"\\nCategorical Features (Most Common):\")\n",
    "        for col, stats in profile['categorical'].items():\n",
    "            print(f\"  {col}: {stats['most_common']} ({stats['percentage']:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521277b",
   "metadata": {},
   "source": [
    "## 6. Prepare Data untuk Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83283839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for classification\n",
    "def prepare_classification_data(df, numerical_cols, categorical_cols, target_col='cluster'):\n",
    "    \"\"\"\n",
    "    Prepare data for classification models\n",
    "    \"\"\"\n",
    "    # Select features (exclude target)\n",
    "    feature_cols = [col for col in numerical_cols + categorical_cols if col in df.columns]\n",
    "    \n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target_col].copy()\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        if col in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            X[col] = le.fit_transform(X[col].astype(str))\n",
    "            label_encoders[col] = le\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    if numerical_cols:\n",
    "        available_num_cols = [col for col in numerical_cols if col in X.columns]\n",
    "        X[available_num_cols] = scaler.fit_transform(X[available_num_cols])\n",
    "    \n",
    "    return X, y, label_encoders, scaler\n",
    "\n",
    "# Prepare classification data\n",
    "X, y, label_encoders, feature_scaler = prepare_classification_data(\n",
    "    df_analysis, final_num_cols, final_cat_cols\n",
    ")\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Feature columns: {list(X.columns)}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207849ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "print(f\"\\nTraining target distribution:\\n{y_train.value_counts().sort_index()}\")\n",
    "print(f\"\\nTest target distribution:\\n{y_test.value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218835be",
   "metadata": {},
   "source": [
    "## 7. Training Multiple Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b715188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and hyperparameters\n",
    "models_config = {\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [10, 20, None],\n",
    "            'min_samples_split': [2, 5]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'model': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "        'params': {\n",
    "            'n_estimators': [100, 200],\n",
    "            'max_depth': [3, 6],\n",
    "            'learning_rate': [0.01, 0.1]\n",
    "        }\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model': SVC(random_state=42),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Model configurations ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models with hyperparameter tuning\n",
    "def train_models(models_config, X_train, y_train, cv=3):\n",
    "    \"\"\"\n",
    "    Train multiple models with hyperparameter tuning\n",
    "    \"\"\"\n",
    "    trained_models = {}\n",
    "    \n",
    "    for model_name, config in models_config.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        # Grid search for hyperparameter tuning\n",
    "        grid_search = GridSearchCV(\n",
    "            config['model'],\n",
    "            config['params'],\n",
    "            cv=cv,\n",
    "            scoring='accuracy',\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Fit the model\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Store results\n",
    "        trained_models[model_name] = {\n",
    "            'model': grid_search.best_estimator_,\n",
    "            'best_params': grid_search.best_params_,\n",
    "            'best_score': grid_search.best_score_,\n",
    "            'grid_search': grid_search\n",
    "        }\n",
    "        \n",
    "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "    \n",
    "    return trained_models\n",
    "\n",
    "# Train all models\n",
    "trained_models = train_models(models_config, X_train, y_train)\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32efbc96",
   "metadata": {},
   "source": [
    "## 8. Model Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e50a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "def evaluate_models(trained_models, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate all trained models and create comparison\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    predictions = {}\n",
    "    \n",
    "    for model_name, model_info in trained_models.items():\n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        predictions[model_name] = y_pred\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1,\n",
    "            'Best_CV_Score': model_info['best_score']\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, predictions\n",
    "\n",
    "# Evaluate models\n",
    "results_df, model_predictions = evaluate_models(trained_models, X_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "display(results_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9945c756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "def plot_model_comparison(results_df):\n",
    "    \"\"\"\n",
    "    Create visualizations for model comparison\n",
    "    \"\"\"\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        bars = ax.bar(results_df['Model'], results_df[metric])\n",
    "        ax.set_title(f'{metric} Comparison')\n",
    "        ax.set_ylabel(metric)\n",
    "        ax.set_ylim(0, 1)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                   f'{height:.3f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Overall comparison radar chart\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Prepare data for grouped bar chart\n",
    "    x = np.arange(len(results_df))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.bar(x + i*width, results_df[metric], width, label=metric)\n",
    "    \n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Model Performance Comparison')\n",
    "    plt.xticks(x + width*1.5, results_df['Model'])\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create comparison plots\n",
    "plot_model_comparison(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4965f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for each model\n",
    "def plot_confusion_matrices(model_predictions, y_test):\n",
    "    \"\"\"\n",
    "    Plot confusion matrices for all models\n",
    "    \"\"\"\n",
    "    n_models = len(model_predictions)\n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
    "    \n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (model_name, y_pred) in enumerate(model_predictions.items()):\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   ax=axes[i], cbar=True)\n",
    "        axes[i].set_title(f'{model_name}\\nConfusion Matrix')\n",
    "        axes[i].set_xlabel('Predicted')\n",
    "        axes[i].set_ylabel('Actual')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrices\n",
    "plot_confusion_matrices(model_predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e165be6e",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6117f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "def get_feature_importance(trained_models, feature_names):\n",
    "    \"\"\"\n",
    "    Extract feature importance from trained models\n",
    "    \"\"\"\n",
    "    importance_data = {}\n",
    "    \n",
    "    for model_name, model_info in trained_models.items():\n",
    "        model = model_info['model']\n",
    "        \n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            # Tree-based models (Random Forest, XGBoost)\n",
    "            importance_data[model_name] = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            # Linear models (SVM with linear kernel)\n",
    "            importance_data[model_name] = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            # For other models, try to get permutation importance\n",
    "            print(f\"No direct feature importance available for {model_name}\")\n",
    "            importance_data[model_name] = np.zeros(len(feature_names))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    importance_df = pd.DataFrame(importance_data, index=feature_names)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance_df = get_feature_importance(trained_models, X.columns)\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "display(feature_importance_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "def plot_feature_importance(importance_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Plot feature importance for each model\n",
    "    \"\"\"\n",
    "    models = importance_df.columns\n",
    "    n_models = len(models)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_models, figsize=(6*n_models, 8))\n",
    "    \n",
    "    if n_models == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        # Get top features\n",
    "        top_features = importance_df[model].nlargest(top_n)\n",
    "        \n",
    "        # Create horizontal bar plot\n",
    "        axes[i].barh(range(len(top_features)), top_features.values)\n",
    "        axes[i].set_yticks(range(len(top_features)))\n",
    "        axes[i].set_yticklabels(top_features.index)\n",
    "        axes[i].set_xlabel('Importance')\n",
    "        axes[i].set_title(f'{model}\\nTop {top_n} Features')\n",
    "        axes[i].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Combined feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Calculate average importance across models\n",
    "    avg_importance = importance_df.mean(axis=1).nlargest(top_n)\n",
    "    \n",
    "    plt.barh(range(len(avg_importance)), avg_importance.values)\n",
    "    plt.yticks(range(len(avg_importance)), avg_importance.index)\n",
    "    plt.xlabel('Average Importance')\n",
    "    plt.title(f'Top {top_n} Features (Average Across All Models)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot feature importance\n",
    "plot_feature_importance(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81266cc7",
   "metadata": {},
   "source": [
    "## 10. Export Results ke Excel/CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faedbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare all results for export\n",
    "def prepare_export_data():\n",
    "    \"\"\"\n",
    "    Prepare all analysis results for export\n",
    "    \"\"\"\n",
    "    export_data = {}\n",
    "    \n",
    "    # 1. Original data with cluster assignments\n",
    "    export_data['data_with_clusters'] = df_analysis.copy()\n",
    "    \n",
    "    # 2. Cluster profiles summary\n",
    "    cluster_summary = []\n",
    "    for cluster_name, profile in cluster_profiles.items():\n",
    "        summary_row = {'Cluster': cluster_name, 'Size': profile['size']}\n",
    "        \n",
    "        # Add numerical summaries\n",
    "        if 'numerical' in profile and not profile['numerical'].empty:\n",
    "            for col in profile['numerical'].columns:\n",
    "                summary_row[f'{col}_mean'] = profile['numerical'].loc['mean', col]\n",
    "        \n",
    "        # Add categorical summaries\n",
    "        if 'categorical' in profile:\n",
    "            for col, stats in profile['categorical'].items():\n",
    "                summary_row[f'{col}_most_common'] = stats['most_common']\n",
    "                summary_row[f'{col}_percentage'] = stats['percentage']\n",
    "        \n",
    "        cluster_summary.append(summary_row)\n",
    "    \n",
    "    export_data['cluster_profiles'] = pd.DataFrame(cluster_summary)\n",
    "    \n",
    "    # 3. Model performance comparison\n",
    "    export_data['model_performance'] = results_df.copy()\n",
    "    \n",
    "    # 4. Feature importance\n",
    "    export_data['feature_importance'] = feature_importance_df.copy()\n",
    "    \n",
    "    # 5. Model predictions\n",
    "    predictions_df = pd.DataFrame(model_predictions)\n",
    "    predictions_df['actual'] = y_test.values\n",
    "    predictions_df.index = y_test.index\n",
    "    export_data['predictions'] = predictions_df\n",
    "    \n",
    "    return export_data\n",
    "\n",
    "# Prepare export data\n",
    "export_data = prepare_export_data()\n",
    "\n",
    "print(\"Export data prepared!\")\n",
    "for key, df in export_data.items():\n",
    "    print(f\"{key}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9747acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Excel\n",
    "def export_to_excel(export_data, filename='kip_kuliah_analysis_results.xlsx'):\n",
    "    \"\"\"\n",
    "    Export all analysis results to Excel with multiple sheets\n",
    "    \"\"\"\n",
    "    filepath = f'../results/{filename}'\n",
    "    \n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl') as writer:\n",
    "        for sheet_name, df in export_data.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=True)\n",
    "            print(f\"Exported {sheet_name} to Excel\")\n",
    "    \n",
    "    print(f\"\\nAll results exported to: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# Export to CSV files\n",
    "def export_to_csv(export_data, folder='csv_results'):\n",
    "    \"\"\"\n",
    "    Export each dataset to separate CSV files\n",
    "    \"\"\"\n",
    "    csv_folder = f'../results/{folder}'\n",
    "    os.makedirs(csv_folder, exist_ok=True)\n",
    "    \n",
    "    exported_files = []\n",
    "    \n",
    "    for name, df in export_data.items():\n",
    "        filepath = f'{csv_folder}/{name}.csv'\n",
    "        df.to_csv(filepath, index=True)\n",
    "        exported_files.append(filepath)\n",
    "        print(f\"Exported {name} to: {filepath}\")\n",
    "    \n",
    "    return exported_files\n",
    "\n",
    "# Export data\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "excel_file = export_to_excel(export_data, f'kip_analysis_{timestamp}.xlsx')\n",
    "csv_files = export_to_csv(export_data, f'csv_results_{timestamp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8b4dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis summary report\n",
    "def create_summary_report():\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary report\n",
    "    \"\"\"\n",
    "    report = f\"\"\"\n",
    "# LAPORAN ANALISIS KIP KULIAH\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "## DATASET OVERVIEW\n",
    "- Total Records: {len(df_analysis)}\n",
    "- Numerical Features: {len(final_num_cols)}\n",
    "- Categorical Features: {len(final_cat_cols)}\n",
    "- Missing Values: {df_analysis.isnull().sum().sum()}\n",
    "\n",
    "## CLUSTERING RESULTS\n",
    "- Algorithm Used: {model_type}\n",
    "- Number of Clusters: {optimal_k}\n",
    "- Cluster Distribution:\n",
    "\"\"\"\n",
    "    \n",
    "    # Add cluster distribution\n",
    "    cluster_dist = df_analysis['cluster'].value_counts().sort_index()\n",
    "    for cluster, count in cluster_dist.items():\n",
    "        percentage = (count / len(df_analysis)) * 100\n",
    "        report += f\"  - Cluster {cluster}: {count} records ({percentage:.1f}%)\\n\"\n",
    "    \n",
    "    # Add model performance\n",
    "    report += \"\\n## MODEL PERFORMANCE\\n\"\n",
    "    best_model = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "    report += f\"- Best Model: {best_model['Model']} (Accuracy: {best_model['Accuracy']:.4f})\\n\"\n",
    "    \n",
    "    for _, row in results_df.iterrows():\n",
    "        report += f\"  - {row['Model']}: Acc={row['Accuracy']:.3f}, F1={row['F1-Score']:.3f}\\n\"\n",
    "    \n",
    "    # Add top features\n",
    "    report += \"\\n## TOP INFLUENTIAL FEATURES\\n\"\n",
    "    avg_importance = feature_importance_df.mean(axis=1).nlargest(5)\n",
    "    for i, (feature, importance) in enumerate(avg_importance.items(), 1):\n",
    "        report += f\"{i}. {feature}: {importance:.4f}\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "# Generate and save summary report\n",
    "summary_report = create_summary_report()\n",
    "report_file = f'../results/analysis_summary_{timestamp}.txt'\n",
    "\n",
    "with open(report_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"SUMMARY REPORT:\")\n",
    "print(\"=\" * 60)\n",
    "print(summary_report)\n",
    "print(f\"\\nFull report saved to: {report_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5352ffe",
   "metadata": {},
   "source": [
    "## Kesimpulan dan Interpretasi\n",
    "\n",
    "### Workflow yang Telah Dilakukan:\n",
    "1. **Data Loading**: Mengombinasikan data pendaftar KIP Kuliah dari tahun 2022-2024\n",
    "2. **Preprocessing**: Menangani missing values dan encoding untuk data campuran\n",
    "3. **Clustering**: Menggunakan K-Prototypes untuk data mixed (numerik + kategorikal)\n",
    "4. **Classification**: Membandingkan Random Forest, XGBoost, dan SVM\n",
    "5. **Evaluation**: Analisis performa model dan feature importance\n",
    "6. **Export**: Hasil dalam format Excel dan CSV untuk review lebih lanjut\n",
    "\n",
    "### Key Insights:\n",
    "- Clustering berhasil mengidentifikasi tipologi pendaftar KIP Kuliah\n",
    "- Model classification dapat memprediksi cluster berdasarkan karakteristik pendaftar\n",
    "- Feature importance menunjukkan faktor-faktor yang paling berpengaruh\n",
    "\n",
    "### Files Generated:\n",
    "- Excel file dengan multiple sheets\n",
    "- CSV files untuk analisis individual\n",
    "- Summary report untuk overview lengkap\n",
    "\n",
    "**Catatan**: Hasil analisis ini dapat digunakan untuk memahami pola pendaftar KIP Kuliah dan mengoptimalkan strategi seleksi."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
